{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf454fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41019b5",
   "metadata": {},
   "source": [
    "Is there any notable pattern of scoring by region? Note: TEIS contracts with three agencies for evaluations (one per grand region) as follows:\n",
    "\n",
    "\n",
    "East TN, First TN and Southeast\n",
    "Greater Nashville, Upper Cumberland, and South Central\n",
    "Northwest, Southwest, and Memphis Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f28be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('..//data/BDI3 All Evals for NSS 11-2023.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a67542a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23947 entries, 0 to 23946\n",
      "Columns: 219 entries, Child ID to Code 10\n",
      "dtypes: datetime64[ns](14), float64(79), object(126)\n",
      "memory usage: 40.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c650083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Child ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Location - Sub Level 1</th>\n",
       "      <th>Program Label</th>\n",
       "      <th>Adaptive Sum of Scaled Scores</th>\n",
       "      <th>Adaptive Developmental Quotient</th>\n",
       "      <th>Adaptive Percentile Rank</th>\n",
       "      <th>Adaptive 95% Confidence Interval</th>\n",
       "      <th>Adaptive RDI</th>\n",
       "      <th>...</th>\n",
       "      <th>Code 1</th>\n",
       "      <th>Code 2</th>\n",
       "      <th>Code 3</th>\n",
       "      <th>Code 4</th>\n",
       "      <th>Code 5</th>\n",
       "      <th>Code 6</th>\n",
       "      <th>Code 7</th>\n",
       "      <th>Code 8</th>\n",
       "      <th>Code 9</th>\n",
       "      <th>Code 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44879</td>\n",
       "      <td>F</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>7.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>16</td>\n",
       "      <td>77-97</td>\n",
       "      <td>39/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47795</td>\n",
       "      <td>F</td>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>Greater Nashville</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>16.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>21</td>\n",
       "      <td>82-96</td>\n",
       "      <td>79/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54340</td>\n",
       "      <td>M</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>First Tennessee</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>8.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>25</td>\n",
       "      <td>81-101</td>\n",
       "      <td>77/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54344</td>\n",
       "      <td>F</td>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>Southeast Tennessee</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>13.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>84</td>\n",
       "      <td>103-123</td>\n",
       "      <td>99/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54515</td>\n",
       "      <td>M</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>Memphis Delta</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5</td>\n",
       "      <td>68-88</td>\n",
       "      <td>1990-09-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Child ID Gender Date of Birth Location - Sub Level 1  \\\n",
       "0    44879      F    2022-09-27              Southwest   \n",
       "1    47795      F    2020-12-23      Greater Nashville   \n",
       "2    54340      M    2021-06-22        First Tennessee   \n",
       "3    54344      F    2022-03-07    Southeast Tennessee   \n",
       "4    54515      M    2021-11-04          Memphis Delta   \n",
       "\n",
       "                  Program Label  Adaptive Sum of Scaled Scores  \\\n",
       "0  BDI-3 Eligibility Evaluation                            7.0   \n",
       "1  BDI-3 Eligibility Evaluation                           16.0   \n",
       "2  BDI-3 Eligibility Evaluation                            8.0   \n",
       "3  BDI-3 Eligibility Evaluation                           13.0   \n",
       "4  BDI-3 Eligibility Evaluation                            5.0   \n",
       "\n",
       "   Adaptive Developmental Quotient Adaptive Percentile Rank  \\\n",
       "0                             85.0                       16   \n",
       "1                             88.0                       21   \n",
       "2                             90.0                       25   \n",
       "3                            115.0                       84   \n",
       "4                             75.0                        5   \n",
       "\n",
       "  Adaptive 95% Confidence Interval         Adaptive RDI  ... Code 1  Code 2  \\\n",
       "0                            77-97                39/90  ...    NaN     NaN   \n",
       "1                            82-96                79/90  ...    NaN     NaN   \n",
       "2                           81-101                77/90  ...    NaN     NaN   \n",
       "3                          103-123                99/90  ...    NaN     NaN   \n",
       "4                            68-88  1990-09-01 00:00:00  ...    NaN     NaN   \n",
       "\n",
       "  Code 3  Code 4  Code 5 Code 6 Code 7 Code 8 Code 9  Code 10  \n",
       "0    NaN     NaN     NaN    NaN    NaN    NaN    NaN      NaN  \n",
       "1    NaN     NaN     NaN    NaN    NaN    NaN    NaN      NaN  \n",
       "2    NaN     NaN     NaN    NaN    NaN    NaN    NaN      NaN  \n",
       "3    NaN     NaN     NaN    NaN    NaN    NaN    NaN      NaN  \n",
       "4    NaN     NaN     NaN    NaN    NaN    NaN    NaN      NaN  \n",
       "\n",
       "[5 rows x 219 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573f722",
   "metadata": {},
   "source": [
    "Group Locations by region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203a8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_groups = {\n",
    "    'East Tennessee': 'East',\n",
    "    'First Tennessee': 'East',\n",
    "    'Southeast Tennessee': 'East',\n",
    "    'Greater Nashville': 'Middle TN',\n",
    "    'Upper Cumberland': 'Middle TN',\n",
    "    'South Central': 'Middle TN',\n",
    "    'Northwest': 'West',\n",
    "    'Southwest': 'West',\n",
    "    'Memphis Delta': 'West'\n",
    "}\n",
    "\n",
    "dataset['Location Group'] = dataset['Location - Sub Level 1'].map(location_groups)\n",
    "\n",
    "dataset['Location Group']. fillna ('Other', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae1324ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = dataset.columns.str.replace (' ', '_')\n",
    "dataset.columns = dataset.columns.str.replace('-','_')\n",
    "dataset.columns = dataset.columns.str.replace ('__','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b409fdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Adaptive_Developmental_Quotient  Adaptive_Percentile_Rank  \\\n",
      "Location_Group                                                              \n",
      "East                                  86.270659                 28.919451   \n",
      "Middle TN                             87.242496                 30.447216   \n",
      "Other                                 91.636364                 42.380645   \n",
      "West                                  87.395396                 30.311982   \n",
      "\n",
      "                Adaptive_95%_Confidence_Interval  Adaptive_RDI  \\\n",
      "Location_Group                                                   \n",
      "East                                         NaN           NaN   \n",
      "Middle TN                                    NaN           NaN   \n",
      "Other                                        NaN           NaN   \n",
      "West                                         NaN           NaN   \n",
      "\n",
      "                Adaptive_Z_Score  Adaptive_T_Score  Adaptive_NCE  \\\n",
      "Location_Group                                                     \n",
      "East                    0.458290         40.848220     37.219964   \n",
      "Middle TN               0.536481         41.494833     38.039068   \n",
      "Other                   0.976000         44.446970     48.272727   \n",
      "West                    0.513493         41.597954     38.264871   \n",
      "\n",
      "                Social_Emotional_Sum_of_Scaled_Scores  \\\n",
      "Location_Group                                          \n",
      "East                                        21.789711   \n",
      "Middle TN                                   22.814352   \n",
      "Other                                       26.406250   \n",
      "West                                        23.928730   \n",
      "\n",
      "                Social_Emotional_Developmental_Quotient  \\\n",
      "Location_Group                                            \n",
      "East                                          92.533248   \n",
      "Middle TN                                     93.965548   \n",
      "Other                                         97.390625   \n",
      "West                                          97.127877   \n",
      "\n",
      "                Social_Emotional_Percentile_Rank  ...  Motor_Fine_Motor_RS  \\\n",
      "Location_Group                                    ...                        \n",
      "East                                   37.346345  ...            24.224965   \n",
      "Middle TN                              40.377263  ...            24.635477   \n",
      "Other                                  47.282031  ...            27.015625   \n",
      "West                                   45.680267  ...            25.040239   \n",
      "\n",
      "                Motor_Fine_Motor_SS  Motor_Fine_Motor_PR  Motor_Fine_Motor_AE  \\\n",
      "Location_Group                                                                  \n",
      "East                       9.791618            50.075063            21.492439   \n",
      "Middle TN                  9.403329            46.901596            21.692909   \n",
      "Other                      8.539062            42.813559            24.898438   \n",
      "West                       9.998295            51.843061            22.524005   \n",
      "\n",
      "                Motor_Fine_Motor_RDI  Motor_Fine_Motor_CSS  \\\n",
      "Location_Group                                               \n",
      "East                             NaN            462.522304   \n",
      "Middle TN                        NaN            464.002955   \n",
      "Other                            NaN            474.703125   \n",
      "West                             NaN            466.261552   \n",
      "\n",
      "                Motor_Fine_Motor_CSS_90%  Motor_Fine_Motor_Z_Score  \\\n",
      "Location_Group                                                       \n",
      "East                                 NaN                  0.687859   \n",
      "Middle TN                            NaN                  0.639201   \n",
      "Other                                NaN                  0.701429   \n",
      "West                                 NaN                  0.765461   \n",
      "\n",
      "                Motor_Fine_Motor_T_Score  Motor_Fine_Motor_NCE  \n",
      "Location_Group                                                  \n",
      "East                           49.297982             49.944496  \n",
      "Middle TN                      48.004629             47.720131  \n",
      "Other                          45.093750             44.245763  \n",
      "West                           49.988065             51.350379  \n",
      "\n",
      "[4 rows x 155 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n",
      "C:\\Users\\ahmee\\AppData\\Local\\Temp\\ipykernel_1752\\314069075.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = location_data[col].mean()\n"
     ]
    }
   ],
   "source": [
    "stats = dataset.columns[6:161]\n",
    "\n",
    "for col in stats:\n",
    "    dataset[col] = pd.to_numeric(dataset[col], errors='coerce')\n",
    "\n",
    "location_data = dataset.groupby('Location_Group')\n",
    "\n",
    "comparison_df = pd.DataFrame()\n",
    "\n",
    "for col in stats:\n",
    "    \n",
    "    comparison_df[col] = location_data[col].mean()  \n",
    "\n",
    "print(comparison_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b0492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eligibility = dataset[dataset[\"Program_Label\"] == 'BDI-3 Eligibility Evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e375fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile= ['Adaptive_Percentile_Rank', 'Social_Emotional_Percentile_Rank', 'Communication_Percentile_Rank','Motor_Percentile_Rank', 'Cognitive_Percentile_Rank']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e7beeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptive_Percentile_Rank</th>\n",
       "      <th>Social_Emotional_Percentile_Rank</th>\n",
       "      <th>Communication_Percentile_Rank</th>\n",
       "      <th>Motor_Percentile_Rank</th>\n",
       "      <th>Cognitive_Percentile_Rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>31.278222</td>\n",
       "      <td>38.886724</td>\n",
       "      <td>26.358831</td>\n",
       "      <td>43.476068</td>\n",
       "      <td>36.680787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Middle TN</th>\n",
       "      <td>31.689797</td>\n",
       "      <td>41.215743</td>\n",
       "      <td>21.775774</td>\n",
       "      <td>43.026590</td>\n",
       "      <td>32.881150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>46.166667</td>\n",
       "      <td>44.183333</td>\n",
       "      <td>8.025000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>33.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>34.197652</td>\n",
       "      <td>49.347771</td>\n",
       "      <td>25.317962</td>\n",
       "      <td>48.576147</td>\n",
       "      <td>35.992600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Adaptive_Percentile_Rank  Social_Emotional_Percentile_Rank  \\\n",
       "Location_Group                                                               \n",
       "East                           31.278222                         38.886724   \n",
       "Middle TN                      31.689797                         41.215743   \n",
       "Other                          46.166667                         44.183333   \n",
       "West                           34.197652                         49.347771   \n",
       "\n",
       "                Communication_Percentile_Rank  Motor_Percentile_Rank  \\\n",
       "Location_Group                                                         \n",
       "East                                26.358831              43.476068   \n",
       "Middle TN                           21.775774              43.026590   \n",
       "Other                                8.025000              27.750000   \n",
       "West                                25.317962              48.576147   \n",
       "\n",
       "                Cognitive_Percentile_Rank  \n",
       "Location_Group                             \n",
       "East                            36.680787  \n",
       "Middle TN                       32.881150  \n",
       "Other                           33.550000  \n",
       "West                            35.992600  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_eligibility.groupby('Location_Group')[percentile].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6bca2bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Location -Sub Level 1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset_eligibility\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation -Sub Level 1\u001b[39m\u001b[38;5;124m'\u001b[39m)[percentile]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   8249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   8250\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 8252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   8253\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8254\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   8255\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   8256\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   8257\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   8258\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   8259\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   8260\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   8261\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   8262\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m    932\u001b[0m         obj,\n\u001b[0;32m    933\u001b[0m         keys,\n\u001b[0;32m    934\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    935\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m    936\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    937\u001b[0m         observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m    938\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m    939\u001b[0m     )\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m    983\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 985\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    988\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Location -Sub Level 1'"
     ]
    }
   ],
   "source": [
    "dataset_eligibility.groupby('Location -Sub Level 1')[percentile].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d12aeb",
   "metadata": {},
   "source": [
    "???? Not understanding why I have the above error. Did not have this error keyerror beforehand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618153d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
