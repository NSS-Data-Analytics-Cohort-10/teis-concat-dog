{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean = pd.read_excel(\"F:\\\\d10\\\\Projects\\\\partnerproject\\\\TEIS_DDA11_DA10-20240126T002836Z-001\\\\TEIS_DDA11_DA10\\\\teis-concat-dog\\\\data\\\\teis_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_columns = ['Adaptive Sum of Scaled Scores', 'Social Emotional Sum of Scaled Scores', 'Communication Sum of Scaled Scores', 'Motor Sum of Scaled Scores', 'Cognitive Sum of Scaled Scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['Social Emotional Sum of Scaled Scores']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24424\\396670503.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#drop cases with no data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Users\\seanm\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6403\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6404\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6405\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6407\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6408\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['Social Emotional Sum of Scaled Scores']"
     ]
    }
   ],
   "source": [
    "#drop cases with no data\n",
    "dataset_clean.dropna(subset=check_columns, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Child ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Location - Sub Level 1</th>\n",
       "      <th>Program Label</th>\n",
       "      <th>Adaptive Sum of Scaled Scores</th>\n",
       "      <th>Adaptive Developmental Quotient</th>\n",
       "      <th>Adaptive Percentile Rank</th>\n",
       "      <th>Adaptive 95% Confidence Interval</th>\n",
       "      <th>Adaptive RDI</th>\n",
       "      <th>...</th>\n",
       "      <th>Code 1</th>\n",
       "      <th>Code 2</th>\n",
       "      <th>Code 3</th>\n",
       "      <th>Code 4</th>\n",
       "      <th>Code 5</th>\n",
       "      <th>Code 6</th>\n",
       "      <th>Code 7</th>\n",
       "      <th>Code 8</th>\n",
       "      <th>Code 9</th>\n",
       "      <th>Code 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44879</td>\n",
       "      <td>F</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>7.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>16</td>\n",
       "      <td>77-97</td>\n",
       "      <td>39/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47795</td>\n",
       "      <td>F</td>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>Greater Nashville</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>16.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>21</td>\n",
       "      <td>82-96</td>\n",
       "      <td>79/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54340</td>\n",
       "      <td>M</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>First Tennessee</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>8.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>25</td>\n",
       "      <td>81-101</td>\n",
       "      <td>77/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54344</td>\n",
       "      <td>F</td>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>Southeast Tennessee</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>13.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>84</td>\n",
       "      <td>103-123</td>\n",
       "      <td>99/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54515</td>\n",
       "      <td>M</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>Memphis Delta</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5</td>\n",
       "      <td>68-88</td>\n",
       "      <td>1990-09-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Child ID Gender Date of Birth Location - Sub Level 1  \\\n",
       "0    44879      F    2022-09-27              Southwest   \n",
       "1    47795      F    2020-12-23      Greater Nashville   \n",
       "2    54340      M    2021-06-22        First Tennessee   \n",
       "3    54344      F    2022-03-07    Southeast Tennessee   \n",
       "4    54515      M    2021-11-04          Memphis Delta   \n",
       "\n",
       "                  Program Label  Adaptive Sum of Scaled Scores  \\\n",
       "0  BDI-3 Eligibility Evaluation                            7.0   \n",
       "1  BDI-3 Eligibility Evaluation                           16.0   \n",
       "2  BDI-3 Eligibility Evaluation                            8.0   \n",
       "3  BDI-3 Eligibility Evaluation                           13.0   \n",
       "4  BDI-3 Eligibility Evaluation                            5.0   \n",
       "\n",
       "   Adaptive Developmental Quotient Adaptive Percentile Rank  \\\n",
       "0                             85.0                       16   \n",
       "1                             88.0                       21   \n",
       "2                             90.0                       25   \n",
       "3                            115.0                       84   \n",
       "4                             75.0                        5   \n",
       "\n",
       "  Adaptive 95% Confidence Interval         Adaptive RDI  ... Code 1  Code 2  \\\n",
       "0                            77-97                39/90  ...    NaN     NaN   \n",
       "1                            82-96                79/90  ...    NaN     NaN   \n",
       "2                           81-101                77/90  ...    NaN     NaN   \n",
       "3                          103-123                99/90  ...    NaN     NaN   \n",
       "4                            68-88  1990-09-01 00:00:00  ...    NaN     NaN   \n",
       "\n",
       "  Code 3  Code 4  Code 5 Code 6 Code 7 Code 8 Code 9  Code 10  \n",
       "0    NaN     NaN     NaN    NaN    NaN    NaN    NaN      NaN  \n",
       "1    NaN     NaN     NaN    NaN    NaN    NaN    NaN      NaN  \n",
       "2    NaN     NaN     NaN    NaN    NaN    NaN    NaN      NaN  \n",
       "3    NaN     NaN     NaN    NaN    NaN    NaN    NaN      NaN  \n",
       "4    NaN     NaN     NaN    NaN    NaN    NaN    NaN      NaN  \n",
       "\n",
       "[5 rows x 219 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group locations\n",
    "location_groups = {\n",
    "    'East Tennessee': 'East',\n",
    "    'First Tennessee': 'East',\n",
    "    'Southeast Tennessee': 'East',\n",
    "    'Greater Nashville': 'Middle TN',\n",
    "    'Upper Cumberland': 'Middle TN',\n",
    "    'South Central': 'Middle TN',\n",
    "    'Northwest': 'West',\n",
    "    'Southwest': 'West',\n",
    "    'Memphis Delta': 'West'\n",
    "}\n",
    "\n",
    "\n",
    "dataset_clean['Location Group'] = dataset_clean['Location - Sub Level 1'].map(location_groups)\n",
    "\n",
    "\n",
    "dataset_clean['Location Group'].fillna('Other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['Location - Sub Level 1']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24424\\3619992229.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataset_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataset_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#drop locations w/ no data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlocation_check\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Location - Sub Level 1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdataset_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocation_check\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Users\\seanm\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6403\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6404\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6405\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6407\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6408\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['Location - Sub Level 1']"
     ]
    }
   ],
   "source": [
    "dataset_clean.columns = dataset_clean.columns.str.replace(' ', '_')\n",
    "dataset_clean.columns = dataset_clean.columns.str.replace('-', '_')\n",
    "dataset_clean.columns = dataset_clean.columns.str.replace('__', '_')\n",
    "#drop locations w/ no data\n",
    "location_check = ['Location - Sub Level 1']\n",
    "dataset_clean.dropna(subset=location_check,how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Adaptive_Developmental_Quotient  Adaptive_Percentile_Rank  \\\n",
      "Location_Group                                                              \n",
      "East                                  86.270659                 28.919451   \n",
      "Middle TN                             87.242496                 30.447216   \n",
      "Other                                 91.636364                 42.380645   \n",
      "West                                  87.395396                 30.311982   \n",
      "\n",
      "                Adaptive_95%_Confidence_Interval  Adaptive_RDI  \\\n",
      "Location_Group                                                   \n",
      "East                                         NaN           NaN   \n",
      "Middle TN                                    NaN           NaN   \n",
      "Other                                        NaN           NaN   \n",
      "West                                         NaN           NaN   \n",
      "\n",
      "                Adaptive_Z_Score  Adaptive_T_Score  Adaptive_NCE  \\\n",
      "Location_Group                                                     \n",
      "East                    0.458290         40.848220     37.219964   \n",
      "Middle TN               0.536481         41.494833     38.039068   \n",
      "Other                   0.976000         44.446970     48.272727   \n",
      "West                    0.513493         41.597954     38.264871   \n",
      "\n",
      "                Social_Emotional_Sum_of_Scaled_Scores  \\\n",
      "Location_Group                                          \n",
      "East                                        21.789711   \n",
      "Middle TN                                   22.814352   \n",
      "Other                                       26.406250   \n",
      "West                                        23.928730   \n",
      "\n",
      "                Social_Emotional_Developmental_Quotient  \\\n",
      "Location_Group                                            \n",
      "East                                          92.533248   \n",
      "Middle TN                                     93.965548   \n",
      "Other                                         97.390625   \n",
      "West                                          97.127877   \n",
      "\n",
      "                Social_Emotional_Percentile_Rank  ...  Motor_Fine_Motor_RS  \\\n",
      "Location_Group                                    ...                        \n",
      "East                                   37.346345  ...            24.224965   \n",
      "Middle TN                              40.377263  ...            24.635477   \n",
      "Other                                  47.282031  ...            27.015625   \n",
      "West                                   45.680267  ...            25.040239   \n",
      "\n",
      "                Motor_Fine_Motor_SS  Motor_Fine_Motor_PR  Motor_Fine_Motor_AE  \\\n",
      "Location_Group                                                                  \n",
      "East                       9.791618            50.075063            21.492439   \n",
      "Middle TN                  9.403329            46.901596            21.692909   \n",
      "Other                      8.539062            42.813559            24.898438   \n",
      "West                       9.998295            51.843061            22.524005   \n",
      "\n",
      "                Motor_Fine_Motor_RDI  Motor_Fine_Motor_CSS  \\\n",
      "Location_Group                                               \n",
      "East                             NaN            462.522304   \n",
      "Middle TN                        NaN            464.002955   \n",
      "Other                            NaN            474.703125   \n",
      "West                             NaN            466.261552   \n",
      "\n",
      "                Motor_Fine_Motor_CSS_90%  Motor_Fine_Motor_Z_Score  \\\n",
      "Location_Group                                                       \n",
      "East                                 NaN                  0.687859   \n",
      "Middle TN                            NaN                  0.639201   \n",
      "Other                                NaN                  0.701429   \n",
      "West                                 NaN                  0.765461   \n",
      "\n",
      "                Motor_Fine_Motor_T_Score  Motor_Fine_Motor_NCE  \n",
      "Location_Group                                                  \n",
      "East                           49.297982             49.944496  \n",
      "Middle TN                      48.004629             47.720131  \n",
      "Other                          45.093750             44.245763  \n",
      "West                           49.988065             51.350379  \n",
      "\n",
      "[4 rows x 155 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_24424\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n"
     ]
    }
   ],
   "source": [
    "stats = dataset_clean.columns[6:161]\n",
    "\n",
    "for col in stats:\n",
    "    dataset_clean[col] = pd.to_numeric(dataset_clean[col], errors='coerce')\n",
    "\n",
    "loc_grouped_data = dataset_clean.groupby('Location_Group')\n",
    "\n",
    "comparison_df = pd.DataFrame()\n",
    "\n",
    "for col in stats:\n",
    "    \n",
    "    comparison_df[col] = loc_grouped_data[col].mean()  \n",
    "\n",
    "print(comparison_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
