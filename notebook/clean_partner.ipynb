{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean = pd.read_excel(\"F:\\\\d10\\\\Projects\\\\partnerproject\\\\TEIS_DDA11_DA10-20240126T002836Z-001\\\\TEIS_DDA11_DA10\\\\teis-concat-dog\\\\data\\\\teis_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_columns = ['Adaptive Sum of Scaled Scores', 'Social Emotional Sum of Scaled Scores', 'Communication Sum of Scaled Scores', 'Motor Sum of Scaled Scores', 'Cognitive Sum of Scaled Scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['Social Emotional Sum of Scaled Scores']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7656\\396670503.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#drop cases with no data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Users\\seanm\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6403\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6404\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6405\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6407\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6408\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['Social Emotional Sum of Scaled Scores']"
     ]
    }
   ],
   "source": [
    "#drop cases with no data\n",
    "dataset_clean.dropna(subset=check_columns, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Child_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date_of_Birth</th>\n",
       "      <th>Location__Sub_Level_1</th>\n",
       "      <th>Program_Label</th>\n",
       "      <th>Adaptive_Sum_of_Scaled_Scores</th>\n",
       "      <th>Adaptive_Developmental_Quotient</th>\n",
       "      <th>Adaptive_Percentile_Rank</th>\n",
       "      <th>Adaptive_95%_Confidence_Interval</th>\n",
       "      <th>Adaptive_RDI</th>\n",
       "      <th>...</th>\n",
       "      <th>Code_2</th>\n",
       "      <th>Code_3</th>\n",
       "      <th>Code_4</th>\n",
       "      <th>Code_5</th>\n",
       "      <th>Code_6</th>\n",
       "      <th>Code_7</th>\n",
       "      <th>Code_8</th>\n",
       "      <th>Code_9</th>\n",
       "      <th>Code_10</th>\n",
       "      <th>Location_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44879</td>\n",
       "      <td>F</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>7.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>16</td>\n",
       "      <td>77-97</td>\n",
       "      <td>39/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47795</td>\n",
       "      <td>F</td>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>Greater Nashville</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>16.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>21</td>\n",
       "      <td>82-96</td>\n",
       "      <td>79/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Middle TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54340</td>\n",
       "      <td>M</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>First Tennessee</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>8.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>25</td>\n",
       "      <td>81-101</td>\n",
       "      <td>77/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54344</td>\n",
       "      <td>F</td>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>Southeast Tennessee</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>13.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>84</td>\n",
       "      <td>103-123</td>\n",
       "      <td>99/90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54515</td>\n",
       "      <td>M</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>Memphis Delta</td>\n",
       "      <td>BDI-3 Eligibility Evaluation</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5</td>\n",
       "      <td>68-88</td>\n",
       "      <td>1990-09-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Child_ID Gender Date_of_Birth Location__Sub_Level_1  \\\n",
       "0    44879      F    2022-09-27             Southwest   \n",
       "1    47795      F    2020-12-23     Greater Nashville   \n",
       "2    54340      M    2021-06-22       First Tennessee   \n",
       "3    54344      F    2022-03-07   Southeast Tennessee   \n",
       "4    54515      M    2021-11-04         Memphis Delta   \n",
       "\n",
       "                  Program_Label  Adaptive_Sum_of_Scaled_Scores  \\\n",
       "0  BDI-3 Eligibility Evaluation                            7.0   \n",
       "1  BDI-3 Eligibility Evaluation                           16.0   \n",
       "2  BDI-3 Eligibility Evaluation                            8.0   \n",
       "3  BDI-3 Eligibility Evaluation                           13.0   \n",
       "4  BDI-3 Eligibility Evaluation                            5.0   \n",
       "\n",
       "   Adaptive_Developmental_Quotient Adaptive_Percentile_Rank  \\\n",
       "0                             85.0                       16   \n",
       "1                             88.0                       21   \n",
       "2                             90.0                       25   \n",
       "3                            115.0                       84   \n",
       "4                             75.0                        5   \n",
       "\n",
       "  Adaptive_95%_Confidence_Interval         Adaptive_RDI  ... Code_2  Code_3  \\\n",
       "0                            77-97                39/90  ...    NaN     NaN   \n",
       "1                            82-96                79/90  ...    NaN     NaN   \n",
       "2                           81-101                77/90  ...    NaN     NaN   \n",
       "3                          103-123                99/90  ...    NaN     NaN   \n",
       "4                            68-88  1990-09-01 00:00:00  ...    NaN     NaN   \n",
       "\n",
       "  Code_4  Code_5  Code_6 Code_7 Code_8 Code_9 Code_10  Location_Group  \n",
       "0    NaN     NaN     NaN    NaN    NaN    NaN     NaN            West  \n",
       "1    NaN     NaN     NaN    NaN    NaN    NaN     NaN       Middle TN  \n",
       "2    NaN     NaN     NaN    NaN    NaN    NaN     NaN            East  \n",
       "3    NaN     NaN     NaN    NaN    NaN    NaN     NaN            East  \n",
       "4    NaN     NaN     NaN    NaN    NaN    NaN     NaN            West  \n",
       "\n",
       "[5 rows x 220 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group locations\n",
    "location_groups = {\n",
    "    'East Tennessee': 'East',\n",
    "    'First Tennessee': 'East',\n",
    "    'Southeast Tennessee': 'East',\n",
    "    'Greater Nashville': 'Middle TN',\n",
    "    'Upper Cumberland': 'Middle TN',\n",
    "    'South Central': 'Middle TN',\n",
    "    'Northwest': 'West',\n",
    "    'Southwest': 'West',\n",
    "    'Memphis Delta': 'West'\n",
    "}\n",
    "\n",
    "\n",
    "dataset_clean['Location Group'] = dataset_clean['Location - Sub Level 1'].map(location_groups)\n",
    "\n",
    "\n",
    "dataset_clean['Location Group'].fillna('Other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean.columns = dataset_clean.columns.str.replace(' ', '_')\n",
    "dataset_clean.columns = dataset_clean.columns.str.replace('-', '_')\n",
    "dataset_clean.columns = dataset_clean.columns.str.replace('__', '_')\n",
    "#drop locations w/ no data\n",
    "location_check = ['Location_Sub_Level_1']\n",
    "dataset_clean.dropna(subset=location_check,how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Adaptive_Developmental_Quotient  Adaptive_Percentile_Rank  \\\n",
      "Location_Group                                                              \n",
      "East                                  86.270659                 28.919451   \n",
      "Middle TN                             87.242496                 30.447216   \n",
      "West                                  87.395396                 30.311982   \n",
      "\n",
      "                Adaptive_95%_Confidence_Interval  Adaptive_RDI  \\\n",
      "Location_Group                                                   \n",
      "East                                         NaN           NaN   \n",
      "Middle TN                                    NaN           NaN   \n",
      "West                                         NaN           NaN   \n",
      "\n",
      "                Adaptive_Z_Score  Adaptive_T_Score  Adaptive_NCE  \\\n",
      "Location_Group                                                     \n",
      "East                    0.458290         40.848220     37.219964   \n",
      "Middle TN               0.536481         41.494833     38.039068   \n",
      "West                    0.513493         41.597954     38.264871   \n",
      "\n",
      "                Social_Emotional_Sum_of_Scaled_Scores  \\\n",
      "Location_Group                                          \n",
      "East                                        21.789711   \n",
      "Middle TN                                   22.814352   \n",
      "West                                        23.928730   \n",
      "\n",
      "                Social_Emotional_Developmental_Quotient  \\\n",
      "Location_Group                                            \n",
      "East                                          92.533248   \n",
      "Middle TN                                     93.965548   \n",
      "West                                          97.127877   \n",
      "\n",
      "                Social_Emotional_Percentile_Rank  ...  Motor_Fine_Motor_RS  \\\n",
      "Location_Group                                    ...                        \n",
      "East                                   37.346345  ...            24.224965   \n",
      "Middle TN                              40.377263  ...            24.635477   \n",
      "West                                   45.680267  ...            25.040239   \n",
      "\n",
      "                Motor_Fine_Motor_SS  Motor_Fine_Motor_PR  Motor_Fine_Motor_AE  \\\n",
      "Location_Group                                                                  \n",
      "East                       9.791618            50.075063            21.492439   \n",
      "Middle TN                  9.403329            46.901596            21.692909   \n",
      "West                       9.998295            51.843061            22.524005   \n",
      "\n",
      "                Motor_Fine_Motor_RDI  Motor_Fine_Motor_CSS  \\\n",
      "Location_Group                                               \n",
      "East                             NaN            462.522304   \n",
      "Middle TN                        NaN            464.002955   \n",
      "West                             NaN            466.261552   \n",
      "\n",
      "                Motor_Fine_Motor_CSS_90%  Motor_Fine_Motor_Z_Score  \\\n",
      "Location_Group                                                       \n",
      "East                                 NaN                  0.687859   \n",
      "Middle TN                            NaN                  0.639201   \n",
      "West                                 NaN                  0.765461   \n",
      "\n",
      "                Motor_Fine_Motor_T_Score  Motor_Fine_Motor_NCE  \n",
      "Location_Group                                                  \n",
      "East                           49.297982             49.944496  \n",
      "Middle TN                      48.004629             47.720131  \n",
      "West                           49.988065             51.350379  \n",
      "\n",
      "[3 rows x 155 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\64036459.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  comparison_df[col] = loc_grouped_data[col].mean()\n"
     ]
    }
   ],
   "source": [
    "stats = dataset_clean.columns[6:161]\n",
    "\n",
    "for col in stats:\n",
    "    dataset_clean[col] = pd.to_numeric(dataset_clean[col], errors='coerce')\n",
    "\n",
    "loc_grouped_data = dataset_clean.groupby('Location_Group')\n",
    "\n",
    "comparison_df = pd.DataFrame()\n",
    "\n",
    "for col in stats:\n",
    "    \n",
    "    comparison_df[col] = loc_grouped_data[col].mean()  \n",
    "\n",
    "print(comparison_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\1359340981.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset_clean['Adaptive_PR'] = dataset_clean['Adaptive_Percentile_Rank']\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\1359340981.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset_clean['Social_Emotional_PR'] = dataset_clean['Social_Emotional_Percentile_Rank']\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\1359340981.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset_clean['Communication_PR'] = dataset_clean['Communication_Percentile_Rank']\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\1359340981.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset_clean['Motor_PR'] = dataset_clean['Motor_Percentile_Rank']\n",
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\1359340981.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset_clean['Cognitive_PR'] = dataset_clean['Cognitive_Percentile_Rank']\n"
     ]
    }
   ],
   "source": [
    "dataset_clean['Adaptive_PR'] = dataset_clean['Adaptive_Percentile_Rank']\n",
    "dataset_clean['Social_Emotional_PR'] = dataset_clean['Social_Emotional_Percentile_Rank']\n",
    "dataset_clean['Communication_PR'] = dataset_clean['Communication_Percentile_Rank']\n",
    "dataset_clean['Motor_PR'] = dataset_clean['Motor_Percentile_Rank']\n",
    "dataset_clean['Cognitive_PR'] = dataset_clean['Cognitive_Percentile_Rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_columns = ['Adaptive_Percentile_Rank', 'Social_Emotional_Percentile_Rank', 'Communication_Percentile_Rank','Motor_Percentile_Rank', 'Cognitive_Percentile_Rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\120496176.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_clean_eligibility[percentile_columns] = dataset_clean_eligibility[percentile_columns].apply(pd.to_numeric, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# dataset_clean_eligibility[percentile_columns] = dataset_clean_eligibility[percentile_columns].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean[percentile_columns] = dataset_clean[percentile_columns].replace('<0.1', '0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean_eligibility = dataset_clean[dataset_clean[\"Program_Label\"] == 'BDI-3 Eligibility Evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptive_Percentile_Rank</th>\n",
       "      <th>Social_Emotional_Percentile_Rank</th>\n",
       "      <th>Communication_Percentile_Rank</th>\n",
       "      <th>Motor_Percentile_Rank</th>\n",
       "      <th>Cognitive_Percentile_Rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>31.278222</td>\n",
       "      <td>38.886724</td>\n",
       "      <td>26.358831</td>\n",
       "      <td>43.476068</td>\n",
       "      <td>36.680787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Middle TN</th>\n",
       "      <td>31.689797</td>\n",
       "      <td>41.215743</td>\n",
       "      <td>21.775774</td>\n",
       "      <td>43.026590</td>\n",
       "      <td>32.881150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>34.197652</td>\n",
       "      <td>49.347771</td>\n",
       "      <td>25.317962</td>\n",
       "      <td>48.576147</td>\n",
       "      <td>35.992600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Adaptive_Percentile_Rank  Social_Emotional_Percentile_Rank  \\\n",
       "Location_Group                                                               \n",
       "East                           31.278222                         38.886724   \n",
       "Middle TN                      31.689797                         41.215743   \n",
       "West                           34.197652                         49.347771   \n",
       "\n",
       "                Communication_Percentile_Rank  Motor_Percentile_Rank  \\\n",
       "Location_Group                                                         \n",
       "East                                26.358831              43.476068   \n",
       "Middle TN                           21.775774              43.026590   \n",
       "West                                25.317962              48.576147   \n",
       "\n",
       "                Cognitive_Percentile_Rank  \n",
       "Location_Group                             \n",
       "East                            36.680787  \n",
       "Middle TN                       32.881150  \n",
       "West                            35.992600  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean_eligibility.groupby('Location_Group')[percentile_columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptive_Percentile_Rank</th>\n",
       "      <th>Social_Emotional_Percentile_Rank</th>\n",
       "      <th>Communication_Percentile_Rank</th>\n",
       "      <th>Motor_Percentile_Rank</th>\n",
       "      <th>Cognitive_Percentile_Rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_Sub_Level_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>East Tennessee</th>\n",
       "      <td>31.680447</td>\n",
       "      <td>37.991972</td>\n",
       "      <td>26.455141</td>\n",
       "      <td>43.493107</td>\n",
       "      <td>35.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Tennessee</th>\n",
       "      <td>28.794468</td>\n",
       "      <td>33.851153</td>\n",
       "      <td>26.932233</td>\n",
       "      <td>41.798857</td>\n",
       "      <td>35.917914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greater Nashville</th>\n",
       "      <td>32.836299</td>\n",
       "      <td>46.608610</td>\n",
       "      <td>23.539583</td>\n",
       "      <td>45.595524</td>\n",
       "      <td>37.476209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Memphis Delta</th>\n",
       "      <td>29.947535</td>\n",
       "      <td>46.297903</td>\n",
       "      <td>22.458269</td>\n",
       "      <td>45.374392</td>\n",
       "      <td>33.693862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northwest</th>\n",
       "      <td>40.716007</td>\n",
       "      <td>54.963889</td>\n",
       "      <td>30.721538</td>\n",
       "      <td>52.527332</td>\n",
       "      <td>40.873013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Central</th>\n",
       "      <td>31.073931</td>\n",
       "      <td>36.709818</td>\n",
       "      <td>19.419725</td>\n",
       "      <td>39.773038</td>\n",
       "      <td>27.850855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southeast Tennessee</th>\n",
       "      <td>32.831507</td>\n",
       "      <td>45.291415</td>\n",
       "      <td>25.615979</td>\n",
       "      <td>45.021918</td>\n",
       "      <td>39.454348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southwest</th>\n",
       "      <td>39.226486</td>\n",
       "      <td>52.174966</td>\n",
       "      <td>27.602525</td>\n",
       "      <td>53.124124</td>\n",
       "      <td>37.577943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upper Cumberland</th>\n",
       "      <td>30.228974</td>\n",
       "      <td>36.575708</td>\n",
       "      <td>21.436106</td>\n",
       "      <td>42.467466</td>\n",
       "      <td>30.624174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Adaptive_Percentile_Rank  \\\n",
       "Location_Sub_Level_1                             \n",
       "East Tennessee                       31.680447   \n",
       "First Tennessee                      28.794468   \n",
       "Greater Nashville                    32.836299   \n",
       "Memphis Delta                        29.947535   \n",
       "Northwest                            40.716007   \n",
       "South Central                        31.073931   \n",
       "Southeast Tennessee                  32.831507   \n",
       "Southwest                            39.226486   \n",
       "Upper Cumberland                     30.228974   \n",
       "\n",
       "                      Social_Emotional_Percentile_Rank  \\\n",
       "Location_Sub_Level_1                                     \n",
       "East Tennessee                               37.991972   \n",
       "First Tennessee                              33.851153   \n",
       "Greater Nashville                            46.608610   \n",
       "Memphis Delta                                46.297903   \n",
       "Northwest                                    54.963889   \n",
       "South Central                                36.709818   \n",
       "Southeast Tennessee                          45.291415   \n",
       "Southwest                                    52.174966   \n",
       "Upper Cumberland                             36.575708   \n",
       "\n",
       "                      Communication_Percentile_Rank  Motor_Percentile_Rank  \\\n",
       "Location_Sub_Level_1                                                         \n",
       "East Tennessee                            26.455141              43.493107   \n",
       "First Tennessee                           26.932233              41.798857   \n",
       "Greater Nashville                         23.539583              45.595524   \n",
       "Memphis Delta                             22.458269              45.374392   \n",
       "Northwest                                 30.721538              52.527332   \n",
       "South Central                             19.419725              39.773038   \n",
       "Southeast Tennessee                       25.615979              45.021918   \n",
       "Southwest                                 27.602525              53.124124   \n",
       "Upper Cumberland                          21.436106              42.467466   \n",
       "\n",
       "                      Cognitive_Percentile_Rank  \n",
       "Location_Sub_Level_1                             \n",
       "East Tennessee                        35.614286  \n",
       "First Tennessee                       35.917914  \n",
       "Greater Nashville                     37.476209  \n",
       "Memphis Delta                         33.693862  \n",
       "Northwest                             40.873013  \n",
       "South Central                         27.850855  \n",
       "Southeast Tennessee                   39.454348  \n",
       "Southwest                             37.577943  \n",
       "Upper Cumberland                      30.624174  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group by Tables - Percentile Rank\n",
    "dataset_clean_eligibility.groupby('Location_Group')[percentile_columns].mean()\n",
    "#Groupby Sub Location for Percentile Rank\n",
    "dataset_clean_eligibility.groupby('Location_Sub_Level_1')[percentile_columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanm\\AppData\\Local\\Temp\\ipykernel_7656\\2068952302.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset_clean['TEST_DATE'] = dataset_clean['Adaptive_Self_Care_Date_of_Testing']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# age stuff\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dataset_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEST_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdaptive_Self_Care_Date_of_Testing\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m dataset_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGE_AT_TEST_YEARS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (dataset_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEST_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m-\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate_of_Birth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear)\n",
      "File \u001b[1;32mF:\\Users\\seanm\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[1;32mF:\\Users\\seanm\\anaconda3\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mF:\\Users\\seanm\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:580\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 580\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# age stuff\n",
    "dataset_clean['TEST_DATE'] = dataset_clean['Adaptive_Self_Care_Date_of_Testing']\n",
    "dataset_clean['AGE_AT_TEST_YEARS'] = (dataset_clean['TEST_DATE'].dt.year - dataset['Date_of_Birth'].dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AGE_AT_TEST_YEARS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m dq_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdaptive_Developmental_Quotient\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSocial_Emotional_Developmental_Quotient\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCommunication_Developmental_Quotient\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMotor_Developmental_Quotient\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCognitive_Developmental_Quotient\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Groupby Region and Age for DQ\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dataset_clean_eligibility\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGE_AT_TEST_YEARS\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m])[dq_columns]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mto_clipboard()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Groupby Sub Location and Age for DQ\u001b[39;00m\n\u001b[0;32m      7\u001b[0m dataset_clean_eligibility\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGE_AT_TEST_YEARS\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation_Sub_Level_1\u001b[39m\u001b[38;5;124m'\u001b[39m])[dq_columns]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mto_clipboard()\n",
      "File \u001b[1;32mF:\\Users\\seanm\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   8249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   8250\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 8252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   8253\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8254\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   8255\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   8256\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   8257\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   8258\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   8259\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   8260\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   8261\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   8262\u001b[0m )\n",
      "File \u001b[1;32mF:\\Users\\seanm\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m    932\u001b[0m         obj,\n\u001b[0;32m    933\u001b[0m         keys,\n\u001b[0;32m    934\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    935\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m    936\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    937\u001b[0m         observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m    938\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m    939\u001b[0m     )\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mF:\\Users\\seanm\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m    983\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 985\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    988\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'AGE_AT_TEST_YEARS'"
     ]
    }
   ],
   "source": [
    "# Groupby Tables - DQ\n",
    "# Create DQ Columns List\n",
    "dq_columns = ['Adaptive_Developmental_Quotient','Social_Emotional_Developmental_Quotient','Communication_Developmental_Quotient','Motor_Developmental_Quotient','Cognitive_Developmental_Quotient']\n",
    "#Groupby Region and Age for DQ\n",
    "dataset_clean_eligibility.groupby(['AGE_AT_TEST_YEARS','Region'])[dq_columns].mean().to_clipboard()\n",
    "#Groupby Sub Location and Age for DQ\n",
    "dataset_clean_eligibility.groupby(['AGE_AT_TEST_YEARS','Location_Sub_Level_1'])[dq_columns].mean().to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
